{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чтение данных\n",
    "\n",
    "Распаковываем архив:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! unrar e -r feedback.csv.rar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения в X_train.csv разделены точкой с запятой (';'). Этот символ также встречается и в комментариях, так что приходится парсить данные руками:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_double_quotes(s):\n",
    "    if not len(s):\n",
    "        return s\n",
    "    \n",
    "    if not '\"' in s:\n",
    "        return s\n",
    "    \n",
    "    first, last = 0, len(s) - 1\n",
    "    while s[first] != '\"':\n",
    "        first += 1\n",
    "    while s[last] != '\"':\n",
    "        last -= 1\n",
    "        \n",
    "    return s[first+1:last]\n",
    "\n",
    "\n",
    "def safe_conversion(val):\n",
    "    try:\n",
    "        val = int(val)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        val = float(val)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return val\n",
    "\n",
    "\n",
    "def read_data(filename):\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        columns = map(remove_double_quotes, lines[0].split(';'))\n",
    "        X = pd.DataFrame(columns=columns)\n",
    "        \n",
    "        for line in lines[1:]:\n",
    "            values = line.split(';')\n",
    "            values = values[:8] + [';'.join(values[8:-2])] + values[-2:]\n",
    "\n",
    "            row = pd.DataFrame(data=np.array(values).reshape(1, -1), columns=columns)\n",
    "            X = pd.concat((X, row), axis=0)  \n",
    "    \n",
    "    for column in X.columns:\n",
    "        X[column] = X[column].apply(lambda x: safe_conversion(remove_double_quotes(x)))\n",
    "\n",
    "    X.comment = X.comment + X.commentNegative + X.commentPositive\n",
    "    \n",
    "    X = X[['userName', 'reting', 'comment']]\n",
    "    X = X.set_index(np.arange(X.shape[0]))\n",
    "    X.comment = X.comment.apply(lambda x: (x.decode('cp1251').encode('utf8')))\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userName</th>\n",
       "      <th>reting</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b2898a81b45310b30beb8fc0c0a9ce1e</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2,5 года работала и все...устала! Лампочка гор...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>538c73d64461e13907bb95c51c38bfbc</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Через 2 месяца после истечении гарантийного ср...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ddca2d0101513a6209db7868eed8be05</td>\n",
       "      <td>4.0</td>\n",
       "      <td>пользуюсь уже три недели. нареканий ни каких н...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>289c20015b3713a82ba5ddf774d996f7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Ребят этот системный блок подойдёт для игры кс...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5576f82d149d4f688644fef2322c63ef</td>\n",
       "      <td>5.0</td>\n",
       "      <td>я считаю, что яри замечательный телефон! Прият...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           userName  reting  \\\n",
       "0  b2898a81b45310b30beb8fc0c0a9ce1e     2.0   \n",
       "1  538c73d64461e13907bb95c51c38bfbc     2.0   \n",
       "2  ddca2d0101513a6209db7868eed8be05     4.0   \n",
       "3  289c20015b3713a82ba5ddf774d996f7     5.0   \n",
       "4  5576f82d149d4f688644fef2322c63ef     5.0   \n",
       "\n",
       "                                             comment  \n",
       "0  2,5 года работала и все...устала! Лампочка гор...  \n",
       "1  Через 2 месяца после истечении гарантийного ср...  \n",
       "2  пользуюсь уже три недели. нареканий ни каких н...  \n",
       "3  Ребят этот системный блок подойдёт для игры кс...  \n",
       "4  я считаю, что яри замечательный телефон! Прият...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = read_data('X_train.csv')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка комментариев:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK (Natural Language ToolKit) -- инструмент для работы с естественным языком:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стемминг -- выделение значащей части слова ( https://ru.wikipedia.org/wiki/%D0%A1%D1%82%D0%B5%D0%BC%D0%BC%D0%B8%D0%BD%D0%B3 ) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer('russian')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стоп-слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "и\n",
      "в\n",
      "во\n",
      "не\n",
      "что\n",
      "он\n",
      "на\n",
      "я\n",
      "с\n",
      "со\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords = stopwords.words('russian')\n",
    "\n",
    "for word in stopwords[:10]:\n",
    "    print word.encode('utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyMorphy2 -- инструмент для работы с текстами на русском языке ( https://pymorphy2.readthedocs.io/en/latest/ ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import pymorphy2\n",
    "\n",
    "#morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметр **clear** отвечает за фильтрацию комментариев:\n",
    "* **none** -- \"как есть\"\n",
    "* **pymorphy** -- оставить только существительные, прилагательные, глаголы, наречия, причастия и деепричастия\n",
    "* **stopwords** -- удалить стоп-слова\n",
    "\n",
    "Параметр **stem** отвечает за преобразование слов:\n",
    "* **none** -- \"как есть\"\n",
    "* **pymorphy** -- привести к начальной форме\n",
    "* **stem** -- стемминг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_single_comment(text, stem='none', clear='none'):\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        token = token.lower()      \n",
    "        token = re.sub(r',-.:;?1//\\|',' ', token)\n",
    "        for word_part in token.split(' '):\n",
    "            if re.compile(u'^[а-яА-Я]+$').match(word_part):\n",
    "                filtered_tokens.append(word_part)   \n",
    "                \n",
    "    if clear == 'pymorphy':\n",
    "        meaningful_pos = ['NOUN', 'ADJF', 'ADJS', 'COMP', 'VERB', 'INFN', 'PRTF', 'PRTS', 'GRND', 'ADVB']\n",
    "        filtered_tokens = [t for t in filtered_tokens if morph.parse(t)[0].tag.POS in meaningful_pos]\n",
    "    \n",
    "    elif clear == 'stopwords':\n",
    "        filtered_tokens = [t for t in filtered_tokens if t not in stopwords]\n",
    "    \n",
    "    if stem == 'stem':\n",
    "        filtered_tokens = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    \n",
    "    elif stem == 'pymorphy':\n",
    "        filtered_tokens = [morph.parse(t)[0].normal_form for t in filtered_tokens]\n",
    "     \n",
    "    return filtered_tokens\n",
    "\n",
    "\n",
    "def preprocess(X, stem='none', clear='none'):\n",
    "    X_preprocessed = pd.DataFrame.copy(X)\n",
    "    for ix in X.index:\n",
    "        comment = X.ix[ix, 'comment'].decode('utf8')\n",
    "        comment_stemmed = preprocess_single_comment(comment, stem=stem, clear=clear)\n",
    "        if stem == 'mystem':\n",
    "            X_preprocessed.ix[ix, 'comment'] = ''.join(comment_stemmed).encode('utf8')\n",
    "        else:\n",
    "            X_preprocessed.ix[ix, 'comment'] = ' '.join(comment_stemmed)\n",
    "        \n",
    "    return X_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаляем стоп-слова, применяем стемминг:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userName</th>\n",
       "      <th>reting</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b2898a81b45310b30beb8fc0c0a9ce1e</td>\n",
       "      <td>2.0</td>\n",
       "      <td>год работа уста лампочк гор</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>538c73d64461e13907bb95c51c38bfbc</td>\n",
       "      <td>2.0</td>\n",
       "      <td>месяц истечен гарантийн срок машинк навернул н...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ddca2d0101513a6209db7868eed8be05</td>\n",
       "      <td>4.0</td>\n",
       "      <td>польз недел нарекан как положительн эмоц вчер ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>289c20015b3713a82ba5ddf774d996f7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>реб системн блок игр кс го средн гастройк</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5576f82d149d4f688644fef2322c63ef</td>\n",
       "      <td>5.0</td>\n",
       "      <td>счита яр замечательн телефон приятн держа рук ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           userName  reting  \\\n",
       "0  b2898a81b45310b30beb8fc0c0a9ce1e     2.0   \n",
       "1  538c73d64461e13907bb95c51c38bfbc     2.0   \n",
       "2  ddca2d0101513a6209db7868eed8be05     4.0   \n",
       "3  289c20015b3713a82ba5ddf774d996f7     5.0   \n",
       "4  5576f82d149d4f688644fef2322c63ef     5.0   \n",
       "\n",
       "                                             comment  \n",
       "0                        год работа уста лампочк гор  \n",
       "1  месяц истечен гарантийн срок машинк навернул н...  \n",
       "2  польз недел нарекан как положительн эмоц вчер ...  \n",
       "3          реб системн блок игр кс го средн гастройк  \n",
       "4  счита яр замечательн телефон приятн держа рук ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_preprocessed = preprocess(X, stem='stem', clear='stopwords')\n",
    "X_preprocessed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разбиение данных на обучение-тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "def split_data(X, mode='folds', k=5, test_size=0.9):\n",
    "    users = np.unique(X.userName)\n",
    "\n",
    "    if mode == 'folds':\n",
    "        np.random.shuffle(users)\n",
    "        folds = []\n",
    "        for i in range(k - 1):\n",
    "            fold_users, users = train_test_split(users, train_size=1.0 / (k - i))\n",
    "            folds.append(fold_users)\n",
    "        \n",
    "        folds.append(users)\n",
    "        return folds\n",
    "    \n",
    "    elif mode == 'train_test':\n",
    "        train_users, test_users = train_test_split(users, test_size=test_size)\n",
    "        return train_users, test_users\n",
    "    \n",
    "    else:\n",
    "        raise NotImplemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формирование признакового пространства\n",
    "\n",
    "https://ru.wikipedia.org/wiki/TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def fit(X):\n",
    "    return TfidfVectorizer(min_df=1).fit(X.comment)\n",
    "\n",
    "def transform(X, model):\n",
    "    return model.transform(X.comment).todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание\n",
    "\n",
    "Модель -- градиентный бустинг:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=0.5, colsample_bylevel=0.9, colsample_bytree=1.0,\n",
      "       gamma=0.8, learning_rate=0.075, max_delta_step=0, max_depth=10,\n",
      "       min_child_weight=1.0, missing=None, n_estimators=80, nthread=-1,\n",
      "       objective='reg:linear', reg_alpha=2, reg_lambda=2,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1.0)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "params = {'min_child_weight': 1.0, \n",
    "          'n_estimators': 80, \n",
    "          'max_depth': 10,  \n",
    "          'subsample': 1.0, \n",
    "          'colsample_bytree': 1.0, \n",
    "          'colsample_bylevel': 0.9, \n",
    "          'reg_alpha': 2, \n",
    "          'reg_lambda': 2,\n",
    "          'learning_rate': 0.075, \n",
    "          'gamma': 0.8}\n",
    "\n",
    "clf = XGBRegressor(**params)\n",
    "print clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика -- RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import itertools\n",
    "\n",
    "def _rmse(y, p):\n",
    "    return np.sqrt(mean_squared_error(y, p))\n",
    "\n",
    "\n",
    "def calculate_rmse(X, train_users, test_users, clf, fit, transform):\n",
    "    rmse_scores = []\n",
    "    X_train = X[X.userName.isin(train_users)]\n",
    "    X_test = X[X.userName.isin(test_users)]\n",
    "        \n",
    "    y_train = np.array(X_train.reting, dtype=float)\n",
    "    y_test = np.array(X_test.reting, dtype=float)\n",
    "        \n",
    "    model = fit(X_train)\n",
    "    X_train = transform(X_train, model)\n",
    "    X_test = transform(X_test, model)\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    p_test = clf.predict(X_test)\n",
    "       \n",
    "    return _rmse(y_test, p_test)\n",
    "\n",
    "\n",
    "def calculate_fold_average_rmse(X, folds, clf, fit, transform, verbose=False):\n",
    "    rmse_scores = []\n",
    "    for i in range(len(folds)):\n",
    "        train_users = list(itertools.chain.from_iterable([folds[j] for j in range(len(folds)) if j != i]))\n",
    "        test_users = folds[i]\n",
    "        \n",
    "        rmse_scores.append(calculate_rmse(X, train_users, test_users, clf, fit, transform))\n",
    "        \n",
    "        if verbose:\n",
    "            print 'FOLD {}\\t RMSE: {}\\n'.format(i + 1, rmse_scores[-1])\n",
    "    \n",
    "    return np.mean(rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Средняя ошибка по 10 фолдам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\t RMSE: 1.11646887397\n",
      "\n",
      "FOLD 2\t RMSE: 1.16393503129\n",
      "\n",
      "FOLD 3\t RMSE: 1.22818381682\n",
      "\n",
      "FOLD 4\t RMSE: 1.10554597944\n",
      "\n",
      "FOLD 5\t RMSE: 1.23827435098\n",
      "\n",
      "FOLD 6\t RMSE: 1.17387415086\n",
      "\n",
      "FOLD 7\t RMSE: 1.08831484728\n",
      "\n",
      "FOLD 8\t RMSE: 1.19796250343\n",
      "\n",
      "FOLD 9\t RMSE: 1.12744300187\n",
      "\n",
      "FOLD 10\t RMSE: 0.937958759245\n",
      "\n",
      "AVERAGE RMSE:  1.13779613152\n"
     ]
    }
   ],
   "source": [
    "folds = split_data(X_preprocessed, mode='folds', k=10)\n",
    "average_rmse = calculate_fold_average_rmse(X_preprocessed, folds, clf, fit, transform, verbose=True)\n",
    "print 'AVERAGE RMSE: ', average_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ошибка на тесте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  1.09967877127\n"
     ]
    }
   ],
   "source": [
    "train_users, test_users = split_data(X_preprocessed, mode='train_test', test_size=0.1)\n",
    "print 'RMSE: ', calculate_rmse(X_preprocessed, train_users, test_users, clf, fit, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
